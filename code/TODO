TODO:
- implement early stopping
- visualize the loss curve
- maby cross-validation
- hyperparameter optimization
    - pooling to decrease feature space
    - batch normalization, dropout
    - layer size, amout of layers, decreasing size layers, stagnating size layers
    - bias and hops: bias=False, k=2
    - also look up in
- different embeddings
- visualization of results
- try out different machine learning models